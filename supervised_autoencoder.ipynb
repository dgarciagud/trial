{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder Supervisado con Keras y MNIST\n",
    "\n",
    "Este notebook muestra cómo construir y entrenar un autoencoder supervisado. A diferencia de un autoencoder tradicional, que solo aprende a reconstruir la entrada, un autoencoder supervisado tiene dos objetivos:\n",
    "\n",
    "1.  **Reconstruir la entrada original:** La tarea principal de un autoencoder.\n",
    "2.  **Clasificar la entrada:** Una tarea de supervisión que utiliza las etiquetas de los datos.\n",
    "\n",
    "Esta doble tarea obliga al espacio latente (la representación codificada) a capturar características que no solo son buenas para la reconstrucción, sino también para la clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cargar y Preprocesar los Datos (MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el conjunto de datos MNIST\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalizar las imágenes a un rango de [0, 1]\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "# Añadir una dimensión para los canales (necesario para las capas convolucionales)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "# Convertir las etiquetas a formato one-hot encoding\n",
    "y_train_cat = to_categorical(y_train, num_classes=10)\n",
    "y_test_cat = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "print(f\"Forma de x_train: {x_train.shape}\")\n",
    "print(f\"Forma de y_train: {y_train_cat.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Construir el Autoencoder Supervisado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(28, 28, 1), name='input_image')\n",
    "\n",
    "# --- Encoder ---\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same', name='encoded_output')(x)\n",
    "# En este punto, la representación codificada tiene la forma (7, 7, 8)\n",
    "\n",
    "# --- Clasificador ---\n",
    "# Esta rama toma la salida del encoder y la usa para la clasificación\n",
    "y = Flatten()(encoded)\n",
    "y = Dense(128, activation='relu')(y)\n",
    "classification_output = Dense(10, activation='softmax', name='classification_output')(y)\n",
    "\n",
    "# --- Decoder ---\n",
    "# Esta rama reconstruye la imagen a partir de la representación codificada\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "reconstruction_output = Conv2D(1, (3, 3), activation='sigmoid', padding='same', name='reconstruction_output')(x)\n",
    "\n",
    "# --- Modelo Completo ---\n",
    "autoencoder = Model(inputs=input_img, outputs=[reconstruction_output, classification_output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compilar el Modelo\n",
    "\n",
    "El modelo tiene dos salidas, por lo que necesitamos especificar una función de pérdida para cada una. También podemos asignar un peso a cada pérdida para priorizar una tarea sobre la otra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(\n",
    "    optimizer='adam',\n",
    "    loss={\n",
    "        'reconstruction_output': 'binary_crossentropy', # Pérdida para la reconstrucción\n",
    "        'classification_output': 'categorical_crossentropy'  # Pérdida para la clasificación\n",
    "    },\n",
    "    loss_weights={\n",
    "        'reconstruction_output': 0.8, # Peso para la reconstrucción\n",
    "        'classification_output': 0.2  # Peso para la clasificación\n",
    "    },\n",
    "    metrics={\n",
    "        'classification_output': 'accuracy' # Métrica para la clasificación\n",
    "    }\n",
    ")\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Entrenar el Modelo\n",
    "\n",
    "Durante el entrenamiento, debemos proporcionar los datos de destino para ambas salidas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = autoencoder.fit(\n",
    "    x_train,\n",
    "    {\n",
    "        'reconstruction_output': x_train, # El objetivo de la reconstrucción es la propia imagen\n",
    "        'classification_output': y_train_cat # El objetivo de la clasificación son las etiquetas\n",
    "    },\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    validation_data=(\n",
    "        x_test, \n",
    "        {\n",
    "            'reconstruction_output': x_test, \n",
    "            'classification_output': y_test_cat\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluar y Visualizar los Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el rendimiento de la clasificación\n",
    "test_loss, reconstruction_loss, classification_loss, classification_accuracy = autoencoder.evaluate(\n",
    "    x_test, \n",
    "    {'reconstruction_output': x_test, 'classification_output': y_test_cat}\n",
    ")\n",
    "\n",
    "print(f\"\\nAccuracy de clasificación en el conjunto de prueba: {classification_accuracy:.4f}\")\n",
    "\n",
    "# Predecir en el conjunto de prueba\n",
    "reconstructed_imgs, classified_labels = autoencoder.predict(x_test)\n",
    "\n",
    "# Visualizar las imágenes originales y reconstruidas\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Imagen original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Imagen reconstruida\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(reconstructed_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
